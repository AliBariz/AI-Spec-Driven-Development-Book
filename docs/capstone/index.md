# Module 4: Vision-Language-Action (VLA) - Capstone

The capstone module integrates all previous learning into a complete autonomous humanoid agent that receives voice commands, plans task sequences using LLMs, navigates obstacles, identifies objects using computer vision, and manipulates objects in simulation.

## Topics Covered

- Voice-to-Action systems using OpenAI Whisper
- LLM-based cognitive planning: converting natural language instructions into ROS 2 action sequences
- Full embodied task pipelines (perception → planning → control)

## Capstone Project

Build an autonomous humanoid agent that:
- Receives a voice command
- Plans a task sequence using an LLM
- Navigates obstacles
- Identifies an object using computer vision
- Manipulates the object in simulation

## Learning Outcomes

Students will be able to build a fully integrated humanoid AI agent demonstrating embodied intelligence.